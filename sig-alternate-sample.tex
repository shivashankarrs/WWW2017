% This is "sig-alternate.tex" V2.1 April 2013
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.5) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V2.0 - May 2012

\documentclass{sig-alternate-05-2015}


\begin{document}

% Copyright
\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
%\doi{10.475/123_4}

% ISBN
%\isbn{123-4567-24-567/08/06}

%Conference
%\conferenceinfo{PLDI '13}{June 16--19, 2013, Seattle, WA, USA}

%\acmPrice{\$15.00}

%
% --- Author Metadata here ---
%\conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Pair-wise Web URI classification for KBD using Distant Supervision and Unlabeled Data}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
%\alignauthor
%S. Shivashankar\\
%       \affaddr{Department of CIS,}\\
%       \affaddr{University of Melbourne}\\
%       \small {shivashankar@student.unimelb.edu.au}
%% 2nd. author
%\alignauthor
%Trevor Cohn\\
%       \affaddr{Department of CIS,}\\
%       \affaddr{University of Melbourne}\\
%	\small {t.cohn@unimelb.edu.au}
%% 3rd. author
%\alignauthor Tim Baldwin\\
%       \affaddr{Department of CIS,}\\
%       \affaddr{University of Melbourne}\\
%       \small{tb@ldwin.net}
}


\maketitle
\begin{abstract}
Entity linking establishes a mapping from entities in given text to URI end-points in a knowledge base (KB), or NIL if the entity is not in the KB. It is an useful task to not only collate information about entities but also to disambiguate them. We explore the relaxed definition of KB from \cite{chisholm2015entity}, that includes any URI which reliably disambiguates linked mentions on the web.  To exploit these resources, we must first infer their existence on the web. We refer to this task as Knowledge Base Discovery (KBD). Web endpoints also yield disambiguated entity mentions. For every entity endpoint we discover, we may recover thousands of entity mentions via inlinks. While the effectiveness of inlink-driven entity disambiguation is known for a single KB setting, this can be extended to leverage inlinks across a collection of automatically discovered web KBs \cite{chisholm2016akbc}. This process has the potential to both improve EL accuracy for well-covered entities and extend the coverage of EL systems by uncovering endpoints for previously unseen entities. We address the problem of pair-wise URI classification based entity disambiguation with distant supervision, by bootstrapping labeled examples using web search, and unlabeled data. We propose a learning to combine approach leveraging distantly supervised examples and unsupervised pair-wise similarity models on entire data.  We empirically evaluate our proposed approach using WePS and ALTA shared task 2016 datasets.

\end{abstract}


%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>  
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}


%
% End generated code
%

%
%  Use this command to print the description
%
%\printccsdesc

% We no longer use \terms command
%\terms{Theory}

\keywords{Entity Linking; Distant Supervision; Learning to Combine; Semi-supervised Learning}

\section{Introduction}

Entity linking (EL) resolves textual mentions to the correct node in a knowledge base (KB). Linking systems typically rely on semantic resources such as Wikipedia, DBPedia to be used as end-points. Though they provide a rich context for entities, these sources do not achieve sufficient recall for all the domains and entities. On the other hand, domain centered sources such as DBLP, IMDb or MusicBrainz would have the depth in coverage for a target domain. It is understandable that a near complete solution would depend on merging resources from multiple knowledge bases (KBs). But an explicit reconciliation of distinct entity sets and heterogeneous sources' schema is a challenging problem in itself \cite{chisholm2016akbc}.  This work is important for growing KBs to include more entities about which we know less -- the long tail. Other work shows that web links can produce models nearly as accurate as those built from richly structured KBs \cite{chisholm2015entity}, but does not include non-Wikipedia entities. We define an entity endpoint as any URI for which inlinks reliably identify and disambiguate named entity mentions. For example, we may observe that inlinks to \url{en.wikipedia.org/wiki/Barack_Obama} are typically mentions of the entity Barack Obama. Links targeting this URI in reference to some other entity are unlikely, so we should consider this an endpoint for the entity Barack Obama. This can help to improve a variety of related challenges such as Web People Search task (WePS\footnote{ http://nlp.uned.es/weps/weps-3}) which is defined as a problem of organizing web search results for a given person name.

% (b) TREC relevance feedback track\footnote{http://trec.nist.gov/data/relevance.feedback.html} had tasks related to relevance classification for a set of 
% documents given a query. We can treat them as similar problems when solved as pair-wise binary document classification. 

In-order to leverage web KB as end-points, valid URIs must be infered on the web, where inlink based disambiguation is a key step. Inlink based disambiguation can be handled as a pair-wise document classification. Pairs are classified as positive if they refer to the same entity and negative otherwise. Providing sufficient labeled examples will be a hard task as it requires enormous resources, but fortunately we can leverage web search based distant supervision to label pairs of URLs automatically. In this work, we propose to leverage web-search based distant supervision and similarity models built on unlabeled data to jointly label examples. This solution is motivated from \cite{hachenbergfinding}, where relation labels from KB are used as queries. Here we use named entities from URLs as context keywords to query.  In \cite{hachenbergfinding}, the reverse task was addressed, to map entities in a KB to web URI end-points. Additionally, we evaluate an extended approach where we use distantly supervised positive examples and models built on unlabeled data to learn a meta classifier model. The intuition is that, if web-search results with context keywords from $URL_{a}$ and domain name from $URL_{b}$, vice versa are used as queries, then a hit in top K search results would indicate that both URIs refer to same entity. But if the top K results do not include $URL_{b}$, then it may not rule out the possibility completely for both URLs to refer to same entity. Especially when K is a less value to increase precision, such as 2 or 5, then due to domain popularity (based on pagerank, HITS) there are chances to miss the expected URI. 

\section{Related Works}

Entity linking and disambiguation have typically relied on Wikipedia \cite{cucerzan2007large, milne2008learning} or a subset \cite{mcnamee2009overview}, or a larger structured resource such as Freebase \cite{zheng2012entity}. Entries in the KB provide a point against which mentions that refer to that entity are clustered. In addition to this, the KBs provide extra information for an entity such as facts, text and other media. Other tasks cluster mentions of the same entity, but without reference to a central KB, namely Cross Document Coreference \cite{bagga1998entity, singh2011large} and Web Person Search \cite{artiles2007semeval}. The task can be more challenging, as we are unable to exploit priors inferred from the KB or leverage information about an entity for clustering.
While an EL KB and a set of coreference clusters are quite different, they both act as aggregation points for mentions of their respective entities.
Mining the content and structure to discover new entities is another important task. There is also substantial work in trying to identify instances of entity
classes from text, exploiting language \cite{hearst1992automatic}, document structure \cite{wang2007language, bing2016distant} and site structure \cite{yang2010reconstruct}. Clustering NIL entities (those that cannot be linked to the KB) has been a focus of the Text Analysis Conference (TAC) Knowledge Base Population
shared tasks from 2011 \cite{heng2011overview}. 

In \cite{hachenbergfinding} authors address the reverse task of identifying good links that correspond to specific KB entities by searching for the entity name in a web search engine and refining the results. This work is important for growing KBs to include more entities about which we know less -- the long
tail. Other work shows that web links can produce models nearly as accurate as those built from richly structured KBs \cite{chisholm2016akbc}, but
does not include non-Wikipedia entities. 

In this work, we treat any valid web URI as an end-point that can be used to disambiguate to an entity. We consider the sub-task of knowledge base discovery on web which requires URI disambiguation based on in-links for entity linking. Since getting access to large amount of labeled data for task is very hard and annotating them manually would incur huge amount of resources, we propose to leverage web search based distant supervision for labeling a subset of URI pairs. We leverage distant supervision labels together with unsupervised pairwise similarity models for classifying all the URI pairs in a transductive fashion. We also evaluate an extended approach that uses distant supervision to provide examples only. Though web search results have been as a feature for clustering documents in WePS \cite{nuray2009exploiting}, we are interested to use it to label a given pair of documents as shown in \cite{hachenbergfinding} where web search based URL classification with entity labels as keywords is shown to work remarkably well. 

Distant supervision is a learning scheme in which a classifier is learned given a weakly labeled training set where the training data is labeled automatically based on heuristics / rules. It has been successfully used for many applications such as relation extraction, sentiment analysis, emotion classification and so on. In this work, we use labeling strategy similar to  \cite{hachenbergfinding}  for obtaining labels  automatically. Also to the best of our knowledge this is the first attempt to leverage distant supervision for labeling positive examples, and unsupervised similarity models on unlabeled data to jointly learn to combine different models.

\section{Proposed Approach}


\section{Experimental Setup}
\section{Conclusions}
\bibliographystyle{abbrv}
\bibliography{sigproc}  
\end{document}
